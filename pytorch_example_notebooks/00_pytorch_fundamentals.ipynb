{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to tensors\n",
    "Tensors are the fundamental building block of machine learning. Their job is to represent data in a numerical way.\n",
    "\n",
    "For example, you could represent an image as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, height, width]`, as in the image has 3 colour channels (red, green, blue), a height of 224 pixels and a width of 224 pixels.\n",
    "\n",
    "In tensor-speak (the language used to describe tensors), the tensor would have three dimensions, one for colour_channels, height and width.\n",
    "\n",
    "#### Creating tensors\n",
    "\n",
    "PyTorch loves tensors. So much so there's a whole documentation page dedicated to the torch.Tensor class.\n",
    "Your first piece of homework is to [https://pytorch.org/docs/stable/tensors.html](read through the documentation on torch.Tensor) for 10-minutes.\n",
    "\n",
    "The first thing we're going to create is a scalar.\n",
    "\n",
    "A scalar is a single number and in tensor-speak it's a zero dimension tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the above printed out `tensor(7)`?\n",
    "\n",
    "That means although scalar is a single number, it's of type `torch.Tensor`.\n",
    "\n",
    "We can check the dimensions of a tensor using the `ndim` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to retrieve the number from the tensor?\n",
    "\n",
    "As in, turn it from `torch.Tensor` to a Python integer?\n",
    "\n",
    "To do we can use the `item()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Python number within a tensor (only works with one-element tensors)\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now let's see a **vector**.\n",
    "\n",
    "A vector is a single dimension tensor but can contain many numbers.\n",
    "\n",
    "As in, you could have a vector `[3, 2]` to describe `[bedrooms, bathrooms]` in your house. Or you could have `[3, 2, 2]` to describe `[bedrooms, bathrooms, car_parks]` in your house.\n",
    "\n",
    "The important trend here is that a vector is flexible in what it can represent (the same with tensors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful, `vector` now contains two 7's, my favourite number.\n",
    "\n",
    "How many dimensions do you think it'll have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of dimensions of vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, that's strange, vector contains two numbers but only has a single dimension.\n",
    "\n",
    "I'll let you in on a trick.\n",
    "\n",
    "You can tell the number of dimensions a tensor in PyTorch has by the number of square brackets on the outside (`[`) and you only need to count one side.\n",
    "\n",
    "How many square brackets does vector have?\n",
    "\n",
    "Another important concept for tensors is their `shape` attribute. The shape tells you how the elements inside them are arranged.\n",
    "\n",
    "Let's check out the shape of vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of vector\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above returns `torch.Size([2])` which means our vector has a shape of `[2]`. This is because of the two elements we placed inside the square brackets `([7, 7])`.\n",
    "\n",
    "Let's now see a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrices are as flexible as vectors, except they've got an extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of dimensions\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MATRIX` has two dimensions (did you count the number of square brakcets on the outside of one side?).\n",
    "\n",
    "What `shape` do you think it will have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the output `torch.Size([2, 2])` because MATRIX is two elements deep and two elements wide.\n",
    "\n",
    "How about we create a tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]])\n",
    "\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to stress that tensors can represent almost anything.\n",
    "\n",
    "The one we just created could be the sales numbers for a steak and almond butter store (two of my favourite foods).\n",
    "\n",
    "How many dimensions do you think it has? (hint: use the square bracket counting trick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of dimensions for TENSOR\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what about its shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of TENSOR\n",
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, it outputs `torch.Size([1, 3, 3])`.\n",
    "\n",
    "The dimensions go outer to inner.\n",
    "\n",
    "That means there's 1 dimension of 3 by 3.\n",
    "\n",
    "#### Random tensors\n",
    "\n",
    "We've established tensors represent some form of data.\n",
    "\n",
    "And machine learning models such as neural networks manipulate and seek patterns within tensors.\n",
    "\n",
    "But when building machine learning models with PyTorch, it's rare you'll create tensors by hand (like what we've being doing).\n",
    "\n",
    "Instead, a machine learning model often starts out with large random tensors of numbers and adjusts these random numbers as it works through data to better represent it.\n",
    "\n",
    "In essence:\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`\n",
    "\n",
    "As a data scientist, you can define how the machine learning model starts (initialization), looks at data (representation) and updates (optimization) its random numbers.\n",
    "\n",
    "We'll get hands on with these steps later on.\n",
    "\n",
    "For now, let's see how to create a tensor of random numbers.\n",
    "\n",
    "We can do so using `torch.rand()` and passing in the size parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6982, 0.2891, 0.9385, 0.8321],\n",
       "         [0.0419, 0.8755, 0.4751, 0.0316],\n",
       "         [0.9144, 0.7624, 0.1508, 0.8958]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3, 4)\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flexibility of `torch.rand()` is that we can adjust the size to be whatever we want.\n",
    "\n",
    "For example, say you wanted a random tensor in the common image shape of `[224, 224, 3]` ([height, width, color_channels]).\n",
    "\n",
    "#### Zeros and ones\n",
    "\n",
    "Sometimes you'll just want to fill tensors with zeros or ones.\n",
    "\n",
    "This happens a lot with masking (like masking some of the values in one tensor with zeros to let a model know not to learn them).\n",
    "\n",
    "Let's create a tensor full of zeros with `torch.zeros()`\n",
    "\n",
    "Again, the size parameter comes into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same to create a tensor of all ones except using `torch.ones()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a range and tensors like\n",
    "\n",
    "Sometimes you might want a range of numbers, such as 1 to 10 or 0 to 100.\n",
    "\n",
    "You can use `torch.arange(start, end, step)` to do so.\n",
    "\n",
    "Where:\n",
    "\n",
    "- start = start of range (e.g. 0)\n",
    "- end = end of range (e.g. 10)\n",
    "- step = how many steps in between each value (e.g. 1)\n",
    "\n",
    "**Note:** In Python, you can use range() to create a range. However in PyTorch, torch.range() is deprecated and may show an error in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you might want one tensor of a certain type with the same shape as another tensor.\n",
    "\n",
    "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
    "\n",
    "To do so you can use `torch.zeros_like(input)` or `torch.ones_like(input)` which return a tensor filled with zeros or ones in the same shape as the input respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Tensor datatypes\n",
    "\n",
    "There are many different [https://pytorch.org/docs/stable/tensors.html#data-types](tensor datatypes available in PyTorch).\n",
    "\n",
    "Some are specific for CPU and some are better for GPU.\n",
    "\n",
    "Getting to know which is which can take some time.\n",
    "\n",
    "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
    "\n",
    "The most common type (and generally the default) is `torch.float32` or `torch.float`.\n",
    "\n",
    "This is referred to as \"32-bit floating point\".\n",
    "\n",
    "But there's also 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`).\n",
    "\n",
    "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
    "\n",
    "The reason for all of these is to do with precision in computing.\n",
    "\n",
    "Precision is the amount of detail used to describe a number.\n",
    "\n",
    "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "\n",
    "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
    "\n",
    "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
    "\n",
    "Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from shape issues (tensor shapes don't match up), two of the other most common issues you'll come across in PyTorch are datatype and device issues.\n",
    "\n",
    "For example, one of tensors is `torch.float32` and the other is `torch.float16` (PyTorch often likes tensors to be the same format).\n",
    "\n",
    "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device).\n",
    "\n",
    "We'll see more of this device talk later on.\n",
    "\n",
    "For now let's create a tensor with `dtype=torch.float16`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
